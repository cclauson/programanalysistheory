%\documentclass[twocolumn,11pt]{article}
\documentclass[11pt]{article}
\usepackage{listings}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage[mathscr]{euscript}
\usepackage{verbatim}
\usepackage {tikz}
\usetikzlibrary {positioning}
%\usepackage {xcolor}
\definecolor {processblue}{cmyk}{0.96,0,0,0}


\begin{document}

\title{Branch Back Formalism for Programs}
\author{C. E. Clauson}
%\affiliation{Somewhere}
\maketitle

\begin{abstract}
We introduce a formula language, called "Branch Back", which is somewhat similar to but also more general than the While programming language which has been defined in literature (source?).  Branch Back is somewhat more general than a programming language, but is rather a class of languages, in which a program is a formula in the language. (TODO: Improve this)
\end{abstract}

\section{Introduction}
The motivation of Branch Back starts in the observation that many models and languages for programs are similar in having finite control, but differ in state external to that finite control, the mutations that the state can undergo, and the ways in which that state impacts the evolution of the program.

For example, a pushdown automaton relies on finite control coupled with a pushdown stack.  The control can push letters onto or pop letters off of the stack, and can branch based on the letter on the top of the stack.  A Turing machine, by contrast, relies on an infinite tape with a head.  This state external to the control can be modified by moving the head and writing a letter to the current position, and the control can test the letter currently under the head.

Additional examples can be produced.  What we notice is that the various cases are similar in many respects, but differ in the following:

\begin{itemize}
\item The state space available to the program external to the finite control
\item The set of operations the control can use to modify that state
\item The set of operations the control can use to test the state for the purposes of branching
\end{itemize}

In the examples given above (pushdown automaton, Turing machine) the reader will be familiar with the finite control being described via an edge-weighted graph, where edges describe transitions and are weighted with conditions and state operations.  Program execution consists of transitioning through states beginning at a start state until some end state is reached (referred to later as a \emph{control flow graph}).

Branch Back is a general formula language powerful enough to describe all programs possible in a paradigm with a given (state, mutator set, condition set) triple, while meeting the following goals:

\begin{itemize}
\item An exceedingly simple language definition
\item Having an operational semantics based on a deterministic term rewrite system (i.e. similar to lambda calculus)
\end{itemize}

Branch Back will be shown to meet these criteria.  Proofs will be provided for equivalence between branch back formulas and control flow graphs, with algorithms for interconversion.

The symbol $\mathbb{B}$ will be used to represent the Boolean set, which has the members \texttt{true} and \texttt{false}.

\section{Branch Back}
For a given sextuple $(S, M, C, \delta_{M}, \delta_{C})$, we define the set $BB(S, M, C, \delta_{M}, \delta_{C})$ as a set of formulas, under the following assumptions:

\begin{itemize}
\item Each member of $S$ (state set) is finitely representable (and thus $S$ is at most countably infinite).
\item Each member of $M$ (primitive state mutations) can be represented by a finite formula (and thus $M$ is at most countably infinite).
\item Each member of $C$ (primitive conditions) can be represented by a finite formula (and thus $C$ is at most countably infinite).
\item The function $\delta_{M} : M \times S \rightarrow S$, which dictates how members of $M$ mutate members of $S$, is a (Turing-)computable function. 
\item The function $\delta_{C} : C \times S \rightarrow \mathbb{B}$, which evaluates members of $C$ at given states in $S$, is a (Turing-)computable function.
\end{itemize}

Additionally, we assume that there exists a set $L$, the label set, which is countably infinite.

We now inductively define the program formulas.  A given program formula is always \emph{open in} some (possibly empty) set contained in $L$, and also always \emph{immediately open in} some (possibly empty) set also contained in $L$.  The inductive definition is as follows:

\begin{enumerate}
\item The special formula \texttt{HALT} is a program formula open in $\emptyset$ and immediately open in $\emptyset$, where $\emptyset$ is the empty set.
\item For every member $l$ of $L$ there exists a program formula $\texttt{branchback(}l\texttt{)}$ open in $\{l\}$ and immediately open in $\{l\}$, where $\{l\}$ is the singleton set containing only $l$.
\item If $m$ is a member of $M$ and $p$ is a program formula open in $L_{O}$ and immediately open in $L_{OI}$, then $m\texttt{;}p$ is a program formula open in $L_{O}$ and immediately open in $\emptyset$, where \texttt{;} is the sequencing operator.
\item If $p_{1}$ is a program formula open in $L_{O,1}$ and immediately open in $L_{OI,1}$, $p_{2}$ is a program formula open in $L_{O,2}$ and immediately open in $L_{OI,2}$, and $c$ is a condition, then \texttt{if} $c$ \texttt{then} $p_{1}$ \texttt{else} $p_{2}$ is a program formula open in $L_{O,1} \cup L_{O,2}$ and immediately open in $\emptyset$.
\item If $l$ is a member of $L$ and $p$ is a program formula open in $L_{O}$, immediately open in $L_{OI}$, and $l \notin L_{OI}$, then $\texttt{label(}l\texttt{,} p\texttt{)}$ is a program formula open in $L_{O} \setminus \{l\}$, the set $L_{O}$ with $l$ removed, and immediately open in $L_{OI}$.
\end{enumerate}

\newtheorem*{immedopencontainedinopen}{Theorem}
\begin{immedopencontainedinopen}
If $p$ is a program formula open in $L_{O}$ and immediately open in $L_{OI}$, then $L_{OI} \subseteq L_{O}$.
\end{immedopencontainedinopen}

\begin{proof}
We prove by structural induction.  The base cases are \texttt{HALT} and the various $\texttt{branchback(}l\texttt{)}$ instances, for both of these $L_{OI} = L_{O}$ which implies $L_{OI} \subseteq L_{O}$.

The cases $m\texttt{;}p$ and \texttt{if} $c$ \texttt{then} $p_{1}$ \texttt{else} $p_{2}$ are easily handled since in both $L_{OI} = \emptyset$, which is contained in every set.

To treat $\texttt{label(}l\texttt{,} p\texttt{)}$, we use the inductive hypothesis, which lets us infer that $L_{OI} \subseteq L_{O}$, where $L_{O}$ and $L_{OI}$ are the sets in which $p$ is open and immediately open respectively.  To complete the inductive step we must show that $L_{OI} \subseteq L_{O} \setminus \{l\}$, but this easily follows from the requirement imposed by the inductive definition that $l \notin L_{OI}$.
\end{proof}

We define a program formula to be \emph{closed} if and only if it is open in $\emptyset$.

\newtheorem*{closedimmedopeninempty}{Theorem}
\begin{closedimmedopeninempty}
If $p$ is a closed program formula then it is immediately open in $\emptyset$.
\end{closedimmedopeninempty}

\begin{proof}
By definition, $p$ is open in $\emptyset$, therefore $L_{OI} \subseteq \emptyset$.  But only $\emptyset$ is contained in $\emptyset$, therefore $L_{OI} = \emptyset$.
\end{proof}

We define Branch Back programs to be exactly those program formulas which are closed.

\section{Execution of A Branch Back Program}

From a high level, the effect of executing a branch back program is to change from one state in $S$ to another state in $S$, which will occur exactly if the program terminates, which it may or may not do.

More specifically, execution occurs by forming a new kind of formula, an \emph{eval formula}, and applying term rewrite rules until no more can be applied.

\subsection{Branch Back Substitution for Program Formulas}

Before looking at eval formulas, we will start by presenting a term rewrite rule for program formulas and analyzing the system using the singleton containing that rule.

The rule is:

\begin{description}
\item[BranchBackSubstProg] $\texttt{label(}l\texttt{,} p\texttt{)} \longrightarrow [\texttt{branchback(}l\texttt{)} \mapsto \texttt{label(}l\texttt{,} p\texttt{)}]p$ (where the notation $[x \mapsto y]f$ denotes the formula $f$ with term $x$ everywhere replaced with the term $y$)
\end{description}

In a term rewrite system a formula is said to be \emph{normal} if no rules can be applied to reduce it.

\newtheorem*{branchbacksubstnormals}{Theorem}
\begin{branchbacksubstnormals}
\texttt{HALT}, $\texttt{branchback(}l\texttt{)}$ for all $l \in L$, programs of form $m\texttt{;}p$ and of form \texttt{if} $c$ \texttt{then} $p_{1}$ \texttt{else} $p_{2}$ are exactly the normal formulas in \textbf{BranchBackSubstProg}.
\end{branchbacksubstnormals}

\begin{proof}
The four cases listed are just exactly the cases of program formulas not of the form $\texttt{label(}l\texttt{,} p\texttt{)}$.  But since programs of the form $\texttt{label(}l\texttt{,} p\texttt{)}$ are exactly those to which \textbf{BranchBackSubstProg} can apply, we are done.
\end{proof}


A term rewrite system is said to be \emph{deterministic} if and only if every formula can be reduced to at most one new formula in a single reduction step, or stated equivalently, if $t$, $t'$ and $t''$ are formulas such that $t \rightarrow t'$ and $t \rightarrow t''$, then $t' = t''$.

\newtheorem*{branchbacksubstisdeterministic}{Theorem}
\begin{branchbacksubstisdeterministic}
\textbf{BranchBackSubstProg} is deterministic.
\end{branchbacksubstisdeterministic}

\begin{proof}
Because our system has only one reduction rule, it's a trivial result that for a given formula, at most one reduction rule can be applied to it.  Also, the rule \textbf{BranchBackSubstProg} can only be applied in one way to a given eligible formula, the way being dictated by the $l \in L$ in the \texttt{label()} at the root.
\end{proof}

A term rewrite system is said to be \emph{normalizing} if for every formula at most a finite number of reductions can be applied before reaching a normal form.

\begin{comment}

\newtheorem*{labelsfinite}{Lemma}
\begin{labelsfinite}
The number of labels in a program formula is finite.
\end{labelsfinite}

\begin{proof}
Trivial from either structural induction, or just the property of formulas being finite.
\end{proof}

\end{comment}

\newtheorem*{formofnonnormalbbsp}{Lemma}
\begin{formofnonnormalbbsp}
Every non-normal formula of \textbf{BranchBackSubstProg} has the form $\texttt{label(}l_{n}\texttt{,} ... \texttt{label(}l_{3}\texttt{,} \texttt{label(}l_{2}\texttt{,} \texttt{label(}l_{1}\texttt{,} p\texttt{)}\texttt{)}\texttt{)} ... \texttt{)}$ where $n \geq 0$ and $p$ is some normal formula.
\end{formofnonnormalbbsp}

\begin{proof}
By structural induction.  We show that for every possible formula either it is normal or it is of the form above.

The base cases \texttt{HALT} and $\texttt{branchback(}l\texttt{)}$ for each $l$ in $L$ are trivial since all of these forms are normal.

The inductive step requires showing that if each of $q_{1}$ and $q_{2}$ is either normal or of the above form, then any formula that can be constructed from it in a single step is.  Both $m\texttt{;}q_{1}$ and \texttt{if} $c$ \texttt{then} $q_{1}$ \texttt{else} $q_{2}$ are easily handled because both are normal.  This leaves $\texttt{label(}l_{i}\texttt{,} q_{1}\texttt{)}$, which can't be normal.  We must show that if $q_{1}$ is either normal or of the form above then this expression is of the form above.

But this is immediate.  If $q_{1}$ is normal, then $\texttt{label(}l_{i}\texttt{,} q_{1}\texttt{)}$ is just the case for $n = 1$.  If $q_{1}$ is of the form above for some $n$, then adding an additional level of nesting makes it also of the above form but with $n + 1$.  This covers both cases, completing the inductive proof.
\end{proof}

\newtheorem*{bbspnorecurse}{Lemma}
\begin{bbspnorecurse}
If
$\texttt{label(}l_{1}\texttt{,} \texttt{label(}l_{2}\texttt{,} \texttt{label(}l_{3}\texttt{,}  ... \texttt{label(}l_{n}\texttt{,} p\texttt{)} ... \texttt{)}\texttt{)}\texttt{)}$ reduces to\\
$\texttt{label(}l_{2}\texttt{,} \texttt{label(}l_{3}\texttt{,}  ... \texttt{label(}l_{n}\texttt{,} p'\texttt{)} ... \texttt{)}\texttt{)}$ via \textbf{BranchBackSubstProg}, and $p$ is normal, then $p'$ is also normal.
\end{bbspnorecurse}

\begin{proof}
(TODO: Prove this, this is where we need the concept of "immediate openness")
\end{proof}

\newtheorem*{branchbacksubstisnormalizing}{Theorem}
\begin{branchbacksubstisnormalizing}
\textbf{BranchBackSubstProg} is normalizing.
\end{branchbacksubstisnormalizing}

\begin{proof}

We prove that every formula of the form
$$\texttt{label(}l_{n}\texttt{,} ... \texttt{label(}l_{3}\texttt{,} \texttt{label(}l_{2}\texttt{,} \texttt{label(}l_{1}\texttt{,} p\texttt{)}\texttt{)}\texttt{)} ... \texttt{)}$$
eventually terminates after a finite number of applications of the rule \textbf{BranchBackSubstProg} by induction on the number of nested $\texttt{label(}l_{i}\texttt{,} ... \texttt{)}$ expressions.

For the base case, we consider $\texttt{label(}l_{1}\texttt{,} p \texttt{)}$ for normal $p$.  A single application of the rule gives $p'$, where $p'$ is normal, therefore $\texttt{label(}l_{1}\texttt{,} p \texttt{)}$ only admits a finite number of operations.

For the inductive step, we assume that $$\texttt{label(}l_{n-1}\texttt{,} ... \texttt{label(}l_{3}\texttt{,} \texttt{label(}l_{2}\texttt{,} \texttt{label(}l_{1}\texttt{,} p\texttt{)}\texttt{)}\texttt{)} ... \texttt{)}$$ admits of only a finite number of applications of \textbf{BranchBackSubstProg} for a general normal $p$, and must show that the same is true with $$\texttt{label(}l_{n}\texttt{,} ... \texttt{label(}l_{3}\texttt{,} \texttt{label(}l_{2}\texttt{,} \texttt{label(}l_{1}\texttt{,} p\texttt{)}\texttt{)}\texttt{)} ... \texttt{)}$$
But this is clear since a single application of \textbf{BranchBackSubstProg} yields $$\texttt{label(}l_{n-1}\texttt{,} ... \texttt{label(}l_{3}\texttt{,} \texttt{label(}l_{2}\texttt{,} \texttt{label(}l_{1}\texttt{,} p'\texttt{)}\texttt{)}\texttt{)} ... \texttt{)}$$ for some normal $p'$, which is guaranteed to be reducible to a normal with a finite number of steps by the inductive hypothesis.

\begin{comment}
Suppose that \textbf{BranchBackSubstProg} is not normalizing, then this implies that we can apply the rule \textbf{BranchBackSubstProg} an arbitrary number of times without ever reaching a normal form.  

Each time \textbf{BranchBackSubstProg} is applied, a substitution is performed on some $l \in L$, therefore if it can be applied infinitely, there must be some infinite sequence $l_{1}, l_{2}, l_{3}, ...$ of labels that we expand.  But because the set of labels in the program is finite, at least some label must occur multiple times in the sequence.
\end{comment}

\end{proof}

\newtheorem*{uniquenormal}{Lemma}
\begin{uniquenormal}
If a term rewrite system is both deterministic and normalizing, then every term in the system has a unique normal that corresponds to it, and which is computable.
\end{uniquenormal}

\begin{proof}
This is basically definitional.  In a deterministic term rewrite system, at each step there is at most one rule that can be applied, and there is no expression which will not be reduced to a normal eventually via some finite number of reduction rule applications.  Therefore our computation is just to apply a rewrite rule to the current expression until it reduces to a normal.
\end{proof}

Because \textbf{BranchBackSubstProg} is both deterministic and normalizing, by the previous lemma each program formula has a unique normal form.  If $p$ is a program formula, we will use the notation $\mathcal{N}_{subst}(p)$ to denote the normal form of $p$ under \textbf{BranchBackSubstProg}.

\newtheorem*{nsubstpreservesopenness}{Theorem}
\begin{nsubstpreservesopenness}
If $p$ is a program formula open in $L_{O}$ then $\mathcal{N}_{subst}(p)$ is also open in $L_{O}$.
\end{nsubstpreservesopenness}

\begin{proof}
(TODO: Do this proof)
\end{proof}

\newtheorem*{openformulanormalforms}{Theorem}
\begin{openformulanormalforms}
If $p$ is a closed program formula then $\mathcal{N}_{subst}(p)$ is either \texttt{HALT}, of form $m\texttt{;}p$ or of form \texttt{if} $c$ \texttt{then} $p_{1}$ \texttt{else} $p_{2}$.
\end{openformulanormalforms}

\begin{proof}
The three cases listed here are exactly the four cases listed for normals of \textbf{BranchBackSubstProg}, minus $\texttt{branchback(}l\texttt{)}$.

Since $p$ is closed and $\mathcal{N}_{subst}$ "preserves closedness," $\mathcal{N}_{subst}(p)$ is also closed.  But because by definition programs of the form $\texttt{branchback(}l\texttt{)}$ are open in ${l}$ and not closed, $\mathcal{N}_{subst}(p)$ cannot have the form $\texttt{branchback(}l\texttt{)}$.

However, since \texttt{HALT} is always normal and formulas of the form $m\texttt{;}p$ or \texttt{if} $c$ \texttt{then} $p_{1}$ \texttt{else} $p_{2}$ can be normal they are possibilities for $\mathcal{N}_{subst}(p)$.
\end{proof}

\subsection{Eval Formulas and Reduction}

We inductively define a new kind of formula, an \emph{eval formula}, in the following way:

\begin{enumerate}
\item Every member of $S$ is an eval formula.
\item If $s$ is a member of $S$ and $p$ is a closed program formula, then $\texttt{eval(}s\texttt{,} p\texttt{)}$ is an eval formula.
\end{enumerate}

Reduction rules are as follows:

\begin{description}
\item[BranchBackSubst] If $p$ is a program formula such that $p \neq \mathcal{N}_{subst}(p)$, then $\texttt{eval(}s\texttt{,} p\texttt{)} \longrightarrow \texttt{eval(}s\texttt{,} \mathcal{N}_{subst}(p)\texttt{)}$.
\item[IfTrue] If $p_{1}$ and $p_{2}$ are program formulas, $s$ is a member of $S$ and $c$ is a member of $C$ such that $\delta_{C}(c, s) = \texttt{true}$ then \\ $\texttt{eval(} s \texttt{, } \texttt{if } c \texttt{ then } p_{1} \texttt{ else } p_{2} \texttt{)} \longrightarrow \texttt{eval(} s \texttt{, } p_{1} \texttt{)}$.
\item[IfFalse] If $p_{1}$ and $p_{2}$ are program formulas, $s$ is a member of $S$ and $c$ is a member of $C$ such that $\delta_{C}(c, s) = \texttt{false}$ then \\ $\texttt{eval(} s \texttt{, } \texttt{if } c \texttt{ then } p_{1} \texttt{ else } p_{2} \texttt{)} \longrightarrow \texttt{eval(} s \texttt{, } p_{2} \texttt{)}$.
\item[MAppl] $\texttt{eval(}s\texttt{, } m\texttt{;}p \texttt{)} \longrightarrow \texttt{eval(} \delta_{M}(m, s)\texttt{, } p \texttt{)}$
\item[Halt] $\texttt{eval(}s\texttt{, } \texttt{HALT)} \longrightarrow s$
\end{description}


(TODO: prove normal forms and determinism, also prove not generally normalizing by showing a specific formula with assumptions about a condition and S)

\section{Program Control Graphs}

(Define formalism for program control graph and operational semantics, operational semantics should not be on the graph itself, but on some other expression, where rewrites depend on graph topology)

(Some latex graph code)

\begin {center}
\begin {tikzpicture}[-latex ,auto ,node distance =4 cm and 5cm ,on grid ,
semithick ,
state/.style ={ rectangle, top color = white , bottom color = processblue!20,
draw, processblue, text=blue, minimum width =1 cm}]
\node[state] (C)
{$1$};
\node[state] (A) [above left=of C] {$0$};
\node[state] (B) [above right =of C] {$2$};
\path (A) edge [loop left] node[left] {$1/4$} (A);
\path (C) edge [bend left =25] node[below =0.15 cm] {$1/2$} (A);
\path (A) edge [bend right = -15] node[below =0.15 cm] {$1/2$} (C);
\path (A) edge [bend left =25] node[above] {$1/4$} (B);
\path (B) edge [bend left =15] node[below =0.15 cm] {$1/2$} (A);
\path (C) edge [bend left =15] node[below =0.15 cm] {$1/2$} (B);
\path (B) edge [bend right = -25] node[below =0.15 cm] {$1/2$} (C);
\end{tikzpicture}
\end{center}

\section{Equivalence of Branch Back Program Formulas and Program Control Graphs}

(These are equivalent, we can actually algorithmically interconvert, this should be shown here)

\begin{comment}

\section{Extensions}

(Some principle should guide extensions, probably that every formula using an extension can be reducible to a formula not using extension, requisite proofs could be produced)

\subsection{While Loops}

(TODO: This should be easy)

\subsection{Terminal/Nonterminal Programs}

(TODO: Basically we should be able to prepend an "if c then q1 else q2" to a program to avoid a large amount of repetition required by more naive approach, probably this can be done by typing programs as terminal/nonterminal)

\subsection{Boolean Operators}

(TODO: Revisit/rewrite/reorg this, originally this was part of the main development but probably it's better treated as an extension...)

We start by inductively defining the set $D$ of \emph{(complex) conditions} in $BB(S, M, C, \delta_{1}, \delta_{2}, L)$ as follows:

\begin{itemize}
\item The special conditions \texttt{true} and \texttt{false} are conditions.
\item Every member of $C$ is a condition.
\item If $c_{1}$ and $c_{2}$ are conditions, then $c_{1} \texttt{\&\&} c_{2}$, $c_{1} \texttt{||} c_{2}$, and $\texttt{!} c_{1}$ are conditions.
\end{itemize}

We notice the following things:
\begin{enumerate}
\item Program formulas can contain condition formulas, but not vice versa.
\item The number of rules pertaining to condition evaluation is comparable in size to those for program evaluation.
\item Condition evaluation can be shown to be simpler in certain mathematical respects than program evaluation.
\end{enumerate}

For these reasons we will describe and analyze condition evaluation here separately from program evaluation.  Note that while these could be done together, this approach makes things somewhat simpler.

We define the following reduction rules for conditions:

\begin{description}

\item[CondPrim] If $c$ is a member of $C$ then $c \rightarrow \delta_{2}(c, s)$.

\item[CondRecurseOr] If $c_{1}$, $c_{1}'$ and $c_{2}$ are conditions and $c_{1} \rightarrow c_{1}'$, then
$c_{1}\texttt{||}c_{2} \rightarrow c_{1}'\texttt{||}c_{2}$.
\item[CondFalseOr] If $c$ is a condition then $\texttt{false||} c \rightarrow c$.
\item[CondTrueOr] If $c$ is a condition then $\texttt{true||} c \rightarrow \texttt{true}$.

\item[CondRecurseAnd] If $c_{1}$, $c_{1}'$ and $c_{2}$ are conditions and $c_{1} \rightarrow c_{1}'$, then
$c_{1}\texttt{\&\&}c_{2} \rightarrow c_{1}'\texttt{\&\&}c_{2}$.
\item[CondFalseAnd] If $c$ is a condition then $\texttt{false\&\&} c \rightarrow \texttt{false}$.
\item[CondTrueAnd] If $c$ is a condition then $\texttt{true\&\&} c \rightarrow c$.

\item[CondRecurseNot] If $c$ and $c'$ are conditions and $c \rightarrow c'$, then
$\texttt{!}c \rightarrow \texttt{!}c'$.
\item[CondTrueNot] $\texttt{!true} \rightarrow \texttt{false}$
\item[CondFalseNot] $\texttt{!false} \rightarrow \texttt{true}$

\end{description}

\newtheorem*{truefalsearenormal}{Theorem}
\begin{truefalsearenormal}
The conditions \texttt{true} and \texttt{false} are normal.
\end{truefalsearenormal}

\begin{proof}
The proof consist of looking through the rules and noticing that there are no reduction rules that apply to the conditions \texttt{true} and \texttt{false}.
\end{proof}

\newtheorem*{conditiondeterminism}{Theorem}
\begin{conditiondeterminism}
The evaluation of a condition is deterministic.
\end{conditiondeterminism}

\begin{proof}

A determinism proof is accomplished by showing that if $t \rightarrow t'$ and $t \rightarrow t''$, then $t' = t''$.  More specifically, we proceed by cases, we use the symbol $t'$ to represent the right hand side of the reduction $t \rightarrow t'$ and for each rule we find a formula for the left hand side of the reduction, and show that it can only be reduced by applying that rule, implying that $t' = t''$.

\textbf{CondPrim} is the only rule that can apply to a primitive condition, i.e., a member of $C$.

If a condition is an or (\texttt{||}), then only \textbf{CondRecurseOr}, \textbf{CondTrueOr} and \textbf{CondFalseOr} potentially apply.  Clearly \textbf{CondTrueOr} and \textbf{CondFalseOr} are mutually exclusive, since the first term of the or cannot be both true or false.  But since both true and false are normal, both are also exclusive with \textbf{CondRecurseOr}, so at most one of these three can apply.

A similar situations exists for the triples \textbf{CondRecurseAnd}, \textbf{CondTrueAnd} and \textbf{CondFalseAnd}, and \textbf{CondRecurseNot}, \textbf{CondTrueNot} and \textbf{CondFalseNot}.

\end{proof}

\newtheorem*{truefalseareuniquelynormal}{Theorem}
\begin{truefalseareuniquelynormal}
No conditions other than \texttt{true} or \texttt{false} are normal.
\end{truefalseareuniquelynormal}

\begin{proof}
We prove this by structural induction.  Specifically, we will prove that each condition is either \texttt{true}, \texttt{false} or reducible.

The base cases are \texttt{true}, \texttt{false} and primitive conditions, primitive conditions are reducible so clearly it's true here.

If $c_{1}$ and $c_{2}$ are both conditions, and $c_{1}$ is either \texttt{true}, \texttt{false} or reducible, then clearly so is $c_{1}\texttt{||}c_{2}$ by \textbf{CondTrueOr}, \textbf{CondFalseOr} and \textbf{CondRecurseOr} respectively.

Analogous reasoning applies to $c_{1}\texttt{\&\&}c_{2}$ and $\texttt{!}c_{1}$.
\end{proof}

\newtheorem*{conditionalsnormalizing}{Theorem}
\begin{conditionalsnormalizing}
Condition evaluation is normalizing.
\end{conditionalsnormalizing}

\begin{proof}
We again prove by structural induction.

The base cases are \texttt{true}, \texttt{false} and primitive conditions, \texttt{true}, \texttt{false} are already normal, and primitive conditions reduce to a normal in one reduction step.

If $c_{1}$ and $c_{2}$ are both conditions which reduce to a normal in a finite number of steps, then to reduce $c_{1}\texttt{||}c_{2}$, we apply \textbf{CondRecurseOr} as many times as it takes to reduce $c_{1}$ to \texttt{true} or \texttt{false}.  If $c_{1}$ reduced to \texttt{true}, then we apply \textbf{CondTrueOr} and arrive at a normal.  Otherwise, we apply \textbf{CondFalseOr} to get $c_{2}$, which we then reduce to \texttt{true} or \texttt{false} in a finite number of steps.  We notice that the total number of steps is finite.
-
Analogous reasoning applies to $c_{1}\texttt{\&\&}c_{2}$ and $\texttt{!}c_{1}$.
\end{proof}

Because conditional evaluation is deterministic and normalizing to the normals \texttt{true} and \texttt{false}, conditional evalution is an effective procedure, and gives a computable function from the set of conditions to the Boolean set $\mathbb{B}$.

From this point we will use the symbol $D$ to denote the set of (non-primitive) conditions, and $\delta_{3} : D \times S \rightarrow \mathbb{B}$ to denote the computable function that maps conditions to $\mathbb{B}$.


\section{Data Flow Analysis of A Generalized While Program}

Let $P$ be a set of partitions of $S$ with the usual conditions, i.e., $P$ is pairwise disjoint and $\bigcup P = S$.  Let us assume the following:

\begin{itemize}
\item There is a computable function $\delta_{3} : M \times P \rightarrow \mathcal{P}(P)$.
\item There is a computable function $\delta_{4} : C \times P \rightarrow \mathcal{P}(\mathbb{B})$
\item $P$ is finite.
\end{itemize}

Then we can compute the function of type P $\rightarrow \mathcal{P}(P)$ that the program corresponds to.

(TODO: Explain...)
(IDEA: Define two forms, "expression form" and "control graph" form for Generalized While Program, explain these, explain how to interconvert)

\section{Other Things}
Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum Lorem ipsum 

\end{comment}


\begin{comment}

The evaluation rules for Generalized While program formulas also occur in the context of a program state from the set $S$, and are as follows.

\begin{description}

\item[EvalPrim] If $m$ is a member of $M$, then $m \rightarrow \texttt{pass}$, accompanied by a change to the program state where the current state $s$ is replaced by $s' = \delta_{1}(m, s)$.
\item[PassElim] If $p$ is a program then $\texttt{pass;}p \rightarrow p$.
\item[SeqRecurse] If $p_{1}$ and $p_{2}$ are programs and $p_{1} \rightarrow p_{1}'$ then $p_{1}\texttt{;}p_{2} \rightarrow p_{1}'\texttt{;}p_{2}$.

\item[CondRecurse] If $p_{1}$ and $p_{2}$ are programs and $c$ and $c'$ are conditions such that $c \rightarrow c'$ then $\texttt{if } c \texttt{ then } p_{1} \texttt{ else } p_{2} \rightarrow \texttt{if } c' \texttt{ then } p_{1} \texttt{ else } p_{2}$.

\item[IfTrue] If $p_{1}$ and $p_{2}$ are programs then $\texttt{if true then } p_{1} \texttt{ else } p_{2} \rightarrow p_{1}$.

\item[IfFalse] If $p_{1}$ and $p_{2}$ are programs then $\texttt{if false then } p_{1} \texttt{ else } p_{2} \rightarrow p_{2}$.

\item[WhileElim] If $c$ is a condition and $p$ is a program then \\ $\texttt{while } c \texttt{ do } p \rightarrow \texttt{if } c \texttt{ then (} p \texttt{; while } c \texttt{ do } p \texttt{) else pass}$.
\end{description}

\newtheorem*{passisnormal}{Theorem}
\begin{passisnormal}
The program \texttt{pass} is normal.
\end{passisnormal}

\begin{proof}
The proof consist of looking through the rules and noticing that there is no rule that applies to the program \texttt{pass}.
\end{proof}

\newtheorem*{determinism}{Theorem}
\begin{determinism}
The evaluation of a Generalized While program is deterministic.
\end{determinism}

\begin{proof}
(TODO: PROVE)
\end{proof}

\newtheorem*{passisuniquelynormal}{Theorem}
\begin{passisuniquelynormal}
No program except for \texttt{pass} is normal.
\end{passisuniquelynormal}

\begin{proof}
(TODO: Do proof...)
\end{proof}

\end{comment}


\end{document}

